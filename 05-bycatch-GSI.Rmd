---
title: "05-bycatch-GSI-assignments"
output: html_notebook
---

This is for the genetic stock identification using rubias with the Northern Fulmar dataset: reference samples were collected at four breeding colonies and mixture samples are bycatch from the Alaskan longline fisheries NOAA Observer Program.

## Background

The background for this analysis is that I have large differences in sample sizes for my fulmar baseline colony dataset and that I know this can cause biased results in assignments - the colonies with smaller sample sizes often lose out.

After a few tests, I determined that downsampling the large colonies changes the distribution of bycatch assignments, with an increased share of the bycatch assigned to the small colonies. This seems to validate the idea that unequal baseline sample sizes are biasing bycatch assignments.

Another set of tests identified 58 (the number of samples for the second-smallest baseline colony) as a much better fit for downsampling than the smallest baseline (36 samples). Downsampling all four colonies to 36 samples eliminated too much of the genotype information.

When downsampling, the problem was that depending on what set.seed was used, different bycatch birds were assigned to colony-of-origin or left unassigned at the 90% probability of assignment threshold.


My plan here is to iterate over multiple set.seed values to generate a dataset that combines the subsampled datasets generated by each downsampled set.seed analysis.


Input bycatch genotypes were cleaned up in `04-tidy-bycatch-genos.Rmd` prior to this analysis.



```{r load-data-and-libraries}
source("R/nofu-functions.R")

library(tidyverse)
library(CKMRsim)
library(stringr)

# I'm reading in the filtered genotype data from `04-tidy-bycatch-genos.Rmd`
no_hi_missers <- read_csv("csv_outputs/bycatch_no_hi_missers_hwe.csv") %>%
  ungroup()
meta <- readRDS("bycatch_data/meta-data-tibble.rds")

```


Before I can perform the rubias assignment...

1. designate the NMFS_DNA_IDs that belong to the mixture and baseline data frames
2. combine genotypes from both data sets to turn alleles into integers and then spread them into the right format to run rubias.

Mixture samples:
```{r add-mixture-column}
# create a data frame for the mixture samples with the sample_type, repunit, and collection columns
mix_ids <- no_hi_missers %>% 
  dplyr::select(NMFS_DNA_ID) %>%
  unique() %>%
  mutate(sample_type = "mixture") %>%
  mutate(repunit = NA)  %>%
  mutate(collection = "bycatch")

# reorder columns
mixture_ids <- mix_ids[,c(2:4,1)]

```

Baseline samples:
```{r read-in-baseline-genos}
# filtered genotypes
baseline <- read_csv("csv_outputs/baseline_no_hi_missers_clean_hwe.csv") %>%
  ungroup()

# sample ids to include for rubias
ref_samples <- read_csv("bycatch_data/baseline_ref_samples_04092019.csv")

# reorder columns
baseline_ids <- ref_samples[, c(2,3,4,1)]

```

517 samples in the ref_samples df
517 in the baseline_no_hi_missers_clean_hwe df as well


## Downsample
Here is where I will take a random slice of the baseline_ids from the colonies with many more samples - the Pribs and the Semidis.

```{r group-numbers}
baseline_ids %>%
  group_by(repunit) %>%
  tally() 

```

Chagulak has the fewest number of samples, with 36, but that removes so much information when I tested so let's equalize to St. Matthew, with 58 samples.

This means I need to split out the Chagulak samples prior to downsampling because there are < 58 samples.


## iterative GSI for the bycatch samples

I wrapped the iterative downsampling into a function. I'll use that with 100 reps, keeping the indivs and colony assignments for 90% probability of assignment.

```{r}
nreps <- 100 # 100 iterations
set.seed(321)
combined_ds_result <- lapply(1:nreps, function(x) downsample_baseline(base_ids = baseline_ids, n_dsample = 58, base_genos = baseline, no_hi_missers = no_hi_missers)[[1]]) %>%
   bind_rows(.id = "iter")

```

summarize those results a bit
```{r}
combined_ds_result %>%
  arrange(indiv) %>%
  group_by(indiv) %>% # if these are unique, there should never be multiple entries for the same sample with different collections
    add_tally(name = "total") %>% # the maximum total number is 100 (the number of reps)
  ungroup() %>%
  group_by(indiv, collection) %>%
  add_tally(name = "n_colony") %>% # this is the number of reps in which this indiv was assigned to this colony 
  mutate(prop_colony = n_colony/total) %>% # the proportion of assignments of this indiv to this colony
  ungroup() %>%
  select(indiv, collection, prop_colony) %>%
  unique() %>%
  ggplot(aes(x = prop_colony)) +
  geom_density()

```


Now take that result and determine which indivs have assignment to a single colony 90% of the time
```{r}
ds_bycatch_colonies <- combined_ds_result %>%
  arrange(indiv) %>%
  group_by(indiv) %>% # if these are unique, there should never be multiple entries for the same sample with different collections
    add_tally(name = "total") %>% # the maximum total number is 100 (the number of reps)
  ungroup() %>%
  group_by(indiv, collection) %>%
  add_tally(name = "n_colony") %>% # this is the number of reps in which this indiv was assigned to this colony 
  mutate(prop_colony = n_colony/total) %>% # the proportion of assignments of this indiv to this colony
  ungroup() %>%
  filter(prop_colony > 0.1) %>% # keep only indivs that were assigned to this colony 90% of the time
  select(indiv, collection) %>%
  unique() 

# just the colony assignments that are > 90% 
keepers <- ds_bycatch_colonies %>%
  group_by(indiv) %>%
  tally() %>%
  filter(n == 1) %>%
  select(-n) %>%
  left_join(ds_bycatch_colonies)

# taking just those birds with a top colony assignment > 90% and adding back on the info about the PofZ
downsampled_bycatch_dataset <- keepers %>%
  left_join(., combined_ds_result) %>% 
  select(indiv, collection, PofZ, z_score) %>% # take the top PofZ per indiv/colony
  group_by(indiv) %>%
  mutate(rank = rank(-PofZ, ties.method = "min")) %>%
  mutate(top_rank = min(rank)) %>%
  filter(rank == top_rank) %>%
  #tally() # there is only a single entry per indiv-collection
  select(-rank, -top_rank) %>%
  left_join(., meta, by = c("indiv" = "NMFS_DNA_ID")) %>%
  select(SAMPLE_ID, indiv, collection, PofZ, z_score) %>%
  rename(NMFS_DNA_ID = indiv) %>%
  ungroup()
  
```


```{r}
# save that output
downsampled_bycatch_dataset %>%
  write_csv("csv_outputs/nofu_bycatch_downsampled_06122020.csv")

```

```{r}
# calculate proportion of the retained bycatch that comes from each colony
downsampled_bycatch_dataset %>%
  group_by(collection) %>%
  tally() %>%
  ungroup() %>%
  mutate(prop = n/sum(n))

```

